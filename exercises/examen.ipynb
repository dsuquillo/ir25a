{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45fdbbc5",
   "metadata": {},
   "source": [
    "Examen Bimestral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88a6713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0c45620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo JSON\n",
    "url = '../data/arxiv_examen.json'\n",
    "data = pd.read_json(url, encoding='utf-8', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1741980f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/murder/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/murder/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/murder/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Descargar recursos necesarios de nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa743c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id                                              title  \\\n",
      "0      704.0001  Calculation of prompt diphoton production cros...   \n",
      "1      704.0002           Sparsity-certifying Graph Decompositions   \n",
      "2      704.0003  The evolution of the Earth-Moon system based o...   \n",
      "3      704.0004  A determinant of Stirling cycle numbers counts...   \n",
      "4      704.0005  From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...   \n",
      "...         ...                                                ...   \n",
      "16995  707.3825  Emergence of noncollinear magnetic ordering in...   \n",
      "16996  707.3826                      More hilltop inflation models   \n",
      "16997  707.3827  Engineering Silicon Nanocrystals: Theoretical ...   \n",
      "16998  707.3828  Structure, bonding and magnetism in cobalt clu...   \n",
      "16999  707.3829  Occupation Statistics of Critical Branching Ra...   \n",
      "\n",
      "                                                abstract  \n",
      "0        A fully differential calculation in perturba...  \n",
      "1        We describe a new algorithm, the $(k,\\ell)$-...  \n",
      "2        The evolution of Earth-Moon system is descri...  \n",
      "3        We show that a determinant of Stirling cycle...  \n",
      "4        In this paper we show how to compute the $\\L...  \n",
      "...                                                  ...  \n",
      "16995    Using first-principles density functional ca...  \n",
      "16996    Using analytic expressions, we explore the p...  \n",
      "16997    We show that the optical and electronic prop...  \n",
      "16998    The structural, electronic and magnetic prop...  \n",
      "16999    Consider a critical nearest neighbor branchi...  \n",
      "\n",
      "[17000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60edd661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            title_tokens  \\\n",
      "0      [calculation, prompt, diphoton, production, cr...   \n",
      "1           [sparsity-certifying, graph, decompositions]   \n",
      "2      [evolution, earth-moon, system, based, dark, m...   \n",
      "3      [determinant, stirling, cycle, numbers, counts...   \n",
      "4           [dyadic, \\lambda_, \\alpha, \\lambda_, \\alpha]   \n",
      "...                                                  ...   \n",
      "16995  [emergence, noncollinear, magnetic, ordering, ...   \n",
      "16996                       [hilltop, inflation, models]   \n",
      "16997  [engineering, silicon, nanocrystals, theoretic...   \n",
      "16998  [structure, bonding, magnetism, cobalt, clusters]   \n",
      "16999  [occupation, statistics, critical, branching, ...   \n",
      "\n",
      "                                         abstract_tokens  \n",
      "0      [fully, differential, calculation, perturbativ...  \n",
      "1      [describe, new, algorithm, k, \\ell, -pebble, g...  \n",
      "2      [evolution, earth-moon, system, described, dar...  \n",
      "3      [show, determinant, stirling, cycle, numbers, ...  \n",
      "4      [paper, show, compute, \\lambda_, \\alpha, norm,...  \n",
      "...                                                  ...  \n",
      "16995  [using, first-principles, density, functional,...  \n",
      "16996  [using, analytic, expressions, explore, parame...  \n",
      "16997  [show, optical, electronic, properties, nanocr...  \n",
      "16998  [structural, electronic, magnetic, properties,...  \n",
      "16999  [consider, critical, nearest, neighbor, branch...  \n",
      "\n",
      "[17000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Definir stopwords en inglés\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Función para preprocesar texto\n",
    "def preprocess_text(text):\n",
    "    # Convertir a minúsculas\n",
    "    text = text.lower()\n",
    "    # Tokenizar palabras\n",
    "    tokens = word_tokenize(text)\n",
    "    # Eliminar stopwords y signos de puntuación\n",
    "    tokens = [word for word in tokens if word not in stop_words and word not in string.punctuation]\n",
    "    return tokens\n",
    "\n",
    "# Aplicar función al título y resumen\n",
    "data['title_tokens'] = data['title'].apply(preprocess_text)\n",
    "data['abstract_tokens'] = data['abstract'].apply(preprocess_text)\n",
    "\n",
    "# Mostrar resultado\n",
    "print(data[['title_tokens', 'abstract_tokens']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33c67f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17000, 44149)\n"
     ]
    }
   ],
   "source": [
    "# Vectorizar\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "# Fit on the combined text from title_tokens and abstract_tokens\n",
    "vectorizer.fit(data['title_tokens'].astype(str) + ' ' + data['abstract_tokens'].astype(str))\n",
    "corpus_vect = vectorizer.transform(data['title_tokens'].astype(str) + ' ' + data['abstract_tokens'].astype(str)) # Transformación\n",
    "print(corpus_vect.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "849fd1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3a853f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para buscar usando TF-IDF\n",
    "def search_tfidf(query, top_k=10):\n",
    "    # Vectorize the query\n",
    "    query_vect = vectorizer.transform([query])\n",
    "\n",
    "    # Calculate cosine similarities between the query and documents\n",
    "    cosine_similarities = cosine_similarity(query_vect, corpus_vect).flatten()\n",
    "\n",
    "    # Create a DataFrame with the results\n",
    "    df_results = pd.DataFrame({'Identificador': data['id'], 'Título': data['title'], 'Resumen': data['abstract'], 'Similitud coseno': cosine_similarities})\n",
    "\n",
    "    # Sort by similarity and get the top results\n",
    "    df_results = df_results.sort_values(by='Similitud coseno', ascending=False)\n",
    "    return df_results.head(top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c85146ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"diphoton production cross sections\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bed3defc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identificador</th>\n",
       "      <th>Título</th>\n",
       "      <th>Resumen</th>\n",
       "      <th>Similitud coseno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>704.0001</td>\n",
       "      <td>Calculation of prompt diphoton production cros...</td>\n",
       "      <td>A fully differential calculation in perturba...</td>\n",
       "      <td>0.393993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15464</th>\n",
       "      <td>707.2294</td>\n",
       "      <td>Search for a High-Mass Diphoton State and Limi...</td>\n",
       "      <td>We have performed a search for new particles...</td>\n",
       "      <td>0.362845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9537</th>\n",
       "      <td>706.0851</td>\n",
       "      <td>Electroweak measurements at the Tevatron</td>\n",
       "      <td>The increasing size of the data samples reco...</td>\n",
       "      <td>0.332994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8315</th>\n",
       "      <td>705.4313</td>\n",
       "      <td>Projectile Fragmentation of $^{86}$Kr at 64 Me...</td>\n",
       "      <td>We measured fragmentation cross sections pro...</td>\n",
       "      <td>0.306359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11499</th>\n",
       "      <td>706.2813</td>\n",
       "      <td>Measurement of the Total Hadronic Cross Sectio...</td>\n",
       "      <td>Using the CLEO III detector, we measure abso...</td>\n",
       "      <td>0.285362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10803</th>\n",
       "      <td>706.2117</td>\n",
       "      <td>Novel Master Formula for Twist-3 Soft-Gluon-Po...</td>\n",
       "      <td>We prove that twist-3 soft-gluon-pole (SGP) ...</td>\n",
       "      <td>0.264567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4351</th>\n",
       "      <td>705.0349</td>\n",
       "      <td>New isotope 44Si and systematics of the produc...</td>\n",
       "      <td>The results of measurements of the productio...</td>\n",
       "      <td>0.257428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11379</th>\n",
       "      <td>706.2693</td>\n",
       "      <td>Reaction cross sections for proton scattering ...</td>\n",
       "      <td>Microscopic optical model potential results ...</td>\n",
       "      <td>0.252194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8251</th>\n",
       "      <td>705.4249</td>\n",
       "      <td>Extrapolation of neutron-rich isotope cross-se...</td>\n",
       "      <td>Using the measured fragmentation cross secti...</td>\n",
       "      <td>0.251028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5053</th>\n",
       "      <td>705.1051</td>\n",
       "      <td>Quasi-elastic neutrino charged-current scatter...</td>\n",
       "      <td>The charged-current quasi-elastic scattering...</td>\n",
       "      <td>0.245088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Identificador                                             Título  \\\n",
       "0           704.0001  Calculation of prompt diphoton production cros...   \n",
       "15464       707.2294  Search for a High-Mass Diphoton State and Limi...   \n",
       "9537        706.0851           Electroweak measurements at the Tevatron   \n",
       "8315        705.4313  Projectile Fragmentation of $^{86}$Kr at 64 Me...   \n",
       "11499       706.2813  Measurement of the Total Hadronic Cross Sectio...   \n",
       "10803       706.2117  Novel Master Formula for Twist-3 Soft-Gluon-Po...   \n",
       "4351        705.0349  New isotope 44Si and systematics of the produc...   \n",
       "11379       706.2693  Reaction cross sections for proton scattering ...   \n",
       "8251        705.4249  Extrapolation of neutron-rich isotope cross-se...   \n",
       "5053        705.1051  Quasi-elastic neutrino charged-current scatter...   \n",
       "\n",
       "                                                 Resumen  Similitud coseno  \n",
       "0        A fully differential calculation in perturba...          0.393993  \n",
       "15464    We have performed a search for new particles...          0.362845  \n",
       "9537     The increasing size of the data samples reco...          0.332994  \n",
       "8315     We measured fragmentation cross sections pro...          0.306359  \n",
       "11499    Using the CLEO III detector, we measure abso...          0.285362  \n",
       "10803    We prove that twist-3 soft-gluon-pole (SGP) ...          0.264567  \n",
       "4351     The results of measurements of the productio...          0.257428  \n",
       "11379    Microscopic optical model potential results ...          0.252194  \n",
       "8251     Using the measured fragmentation cross secti...          0.251028  \n",
       "5053     The charged-current quasi-elastic scattering...          0.245088  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_tfidf(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b6ac49f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25 Search\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "def search_bm25(query,  top_k=10):\n",
    "  # Tokenize the corpus for BM25\n",
    "  tokenized_corpus = data['abstract_tokens'].tolist()\n",
    "\n",
    "  bm25_doc = BM25Okapi(tokenized_corpus)\n",
    "  scores = bm25_doc.get_scores(query)\n",
    "\n",
    "  # Create a DataFrame with the data\n",
    "  df = pd.DataFrame({'Identificador': data['id'], 'Título': data['title'], 'Resumen': data['abstract'], 'Score BM25': scores})\n",
    "  df = df.sort_values(by='Score BM25', ascending=False)\n",
    "  bm25_results = df.head(top_k)\n",
    "  bm25_results\n",
    "  return bm25_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "898ad66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identificador</th>\n",
       "      <th>Título</th>\n",
       "      <th>Resumen</th>\n",
       "      <th>Score BM25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14426</th>\n",
       "      <td>707.1256</td>\n",
       "      <td>The geometry of the critical set of nonlinear ...</td>\n",
       "      <td>We study the critical set C of the nonlinear...</td>\n",
       "      <td>54.005663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13534</th>\n",
       "      <td>707.0364</td>\n",
       "      <td>Polarization types of isogenous Prym-Tyurin va...</td>\n",
       "      <td>Let p:C--&gt;Y be a covering of smooth, project...</td>\n",
       "      <td>49.654692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14278</th>\n",
       "      <td>707.1108</td>\n",
       "      <td>Permutation binomials over finite fields</td>\n",
       "      <td>We prove that if x^m + c*x^n permutes the pr...</td>\n",
       "      <td>46.431785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4327</th>\n",
       "      <td>705.0325</td>\n",
       "      <td>The order of the largest complete minor in a r...</td>\n",
       "      <td>Let ccl(G) denote the order of the largest c...</td>\n",
       "      <td>43.879518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12788</th>\n",
       "      <td>706.4102</td>\n",
       "      <td>Ramsey numbers and the size of graphs</td>\n",
       "      <td>For two graph H and G, the Ramsey number r(H...</td>\n",
       "      <td>43.550299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16486</th>\n",
       "      <td>707.3316</td>\n",
       "      <td>Morita equivalences of cyclotomic Hecke algebr...</td>\n",
       "      <td>We prove a Morita reduction theorem for the ...</td>\n",
       "      <td>43.228933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7751</th>\n",
       "      <td>705.3749</td>\n",
       "      <td>Difference sets and shifted primes</td>\n",
       "      <td>We show that if A is a subset of {1, ..., n}...</td>\n",
       "      <td>42.580936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14272</th>\n",
       "      <td>707.1102</td>\n",
       "      <td>Nonexistence of permutation binomials of certa...</td>\n",
       "      <td>Suppose x^m + c*x^n is a permutation polynom...</td>\n",
       "      <td>41.792553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15782</th>\n",
       "      <td>707.2612</td>\n",
       "      <td>Exceptional covers of surfaces</td>\n",
       "      <td>Consider a finite morphism f:X -&gt; Y of smoot...</td>\n",
       "      <td>39.846724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16842</th>\n",
       "      <td>707.3672</td>\n",
       "      <td>Products of irreducible random matrices in the...</td>\n",
       "      <td>We consider the recursive equation ``x(n+1)=...</td>\n",
       "      <td>39.735954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Identificador                                             Título  \\\n",
       "14426       707.1256  The geometry of the critical set of nonlinear ...   \n",
       "13534       707.0364  Polarization types of isogenous Prym-Tyurin va...   \n",
       "14278       707.1108           Permutation binomials over finite fields   \n",
       "4327        705.0325  The order of the largest complete minor in a r...   \n",
       "12788       706.4102              Ramsey numbers and the size of graphs   \n",
       "16486       707.3316  Morita equivalences of cyclotomic Hecke algebr...   \n",
       "7751        705.3749                 Difference sets and shifted primes   \n",
       "14272       707.1102  Nonexistence of permutation binomials of certa...   \n",
       "15782       707.2612                     Exceptional covers of surfaces   \n",
       "16842       707.3672  Products of irreducible random matrices in the...   \n",
       "\n",
       "                                                 Resumen  Score BM25  \n",
       "14426    We study the critical set C of the nonlinear...   54.005663  \n",
       "13534    Let p:C-->Y be a covering of smooth, project...   49.654692  \n",
       "14278    We prove that if x^m + c*x^n permutes the pr...   46.431785  \n",
       "4327     Let ccl(G) denote the order of the largest c...   43.879518  \n",
       "12788    For two graph H and G, the Ramsey number r(H...   43.550299  \n",
       "16486    We prove a Morita reduction theorem for the ...   43.228933  \n",
       "7751     We show that if A is a subset of {1, ..., n}...   42.580936  \n",
       "14272    Suppose x^m + c*x^n is a permutation polynom...   41.792553  \n",
       "15782    Consider a finite morphism f:X -> Y of smoot...   39.846724  \n",
       "16842    We consider the recursive equation ``x(n+1)=...   39.735954  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_bm25(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e965d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d405f121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando embeddings...\n"
     ]
    }
   ],
   "source": [
    "# Create embeddings for the recipes data\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"Generando embeddings...\")\n",
    "embeddings = model.encode(data['abstract'].tolist(), convert_to_numpy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d30bfe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create index FAISS\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])  # L2 distance\n",
    "index.add(embeddings)  # Add embeddings to the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47edbf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config OpenAI\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fd2eac76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search function\n",
    "def search_faiss(query, top_k=10):\n",
    "    # Create embedding for the query\n",
    "    query_embedding = model.encode([query], convert_to_numpy=True)\n",
    "\n",
    "    # Search in the index\n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "\n",
    "    # Get the results from the original data\n",
    "    results = data.iloc[indices[0]].copy()\n",
    "    results['Distance'] = distances[0]\n",
    "    \n",
    "    return results[['id', 'title', 'abstract', 'Distance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "66b9a07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15545</th>\n",
       "      <td>707.2375</td>\n",
       "      <td>Pion Production by Protons on a Thin Beryllium...</td>\n",
       "      <td>An analysis of inclusive pion production in ...</td>\n",
       "      <td>1.046610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6746</th>\n",
       "      <td>705.2744</td>\n",
       "      <td>Distributions for MSSM Higgs boson + jet produ...</td>\n",
       "      <td>We present pseudorapidity and transverse mom...</td>\n",
       "      <td>1.051520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9537</th>\n",
       "      <td>706.0851</td>\n",
       "      <td>Electroweak measurements at the Tevatron</td>\n",
       "      <td>The increasing size of the data samples reco...</td>\n",
       "      <td>1.055434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7886</th>\n",
       "      <td>705.3884</td>\n",
       "      <td>Inclusive electron spectrum in the region of p...</td>\n",
       "      <td>We have carried out a calculation of the inc...</td>\n",
       "      <td>1.059579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>704.1985</td>\n",
       "      <td>Electromagnetic Higgs production</td>\n",
       "      <td>The cross section for central diffractive Hi...</td>\n",
       "      <td>1.066204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13288</th>\n",
       "      <td>707.0118</td>\n",
       "      <td>Proton Structure Functions at High $Q^{2}$ and...</td>\n",
       "      <td>Neutral and charged current deep inelastic s...</td>\n",
       "      <td>1.066468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14716</th>\n",
       "      <td>707.1546</td>\n",
       "      <td>Producing an Intense, Cool Muon Beam via e+e- ...</td>\n",
       "      <td>We consider a highly unconventional approach...</td>\n",
       "      <td>1.097358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9387</th>\n",
       "      <td>706.0701</td>\n",
       "      <td>Top Pair Production cross-section at the Tevatron</td>\n",
       "      <td>An overview of latest top quark pair product...</td>\n",
       "      <td>1.117400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6433</th>\n",
       "      <td>705.2431</td>\n",
       "      <td>Higher-order Threshold Corrections for Single ...</td>\n",
       "      <td>I discuss single top quark production at the...</td>\n",
       "      <td>1.122415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>704.1429</td>\n",
       "      <td>Light stops in the MSSM parameter space</td>\n",
       "      <td>We consider the regions of the MSSM paramete...</td>\n",
       "      <td>1.133265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                              title  \\\n",
       "15545  707.2375  Pion Production by Protons on a Thin Beryllium...   \n",
       "6746   705.2744  Distributions for MSSM Higgs boson + jet produ...   \n",
       "9537   706.0851           Electroweak measurements at the Tevatron   \n",
       "7886   705.3884  Inclusive electron spectrum in the region of p...   \n",
       "1984   704.1985                   Electromagnetic Higgs production   \n",
       "13288  707.0118  Proton Structure Functions at High $Q^{2}$ and...   \n",
       "14716  707.1546  Producing an Intense, Cool Muon Beam via e+e- ...   \n",
       "9387   706.0701  Top Pair Production cross-section at the Tevatron   \n",
       "6433   705.2431  Higher-order Threshold Corrections for Single ...   \n",
       "1428   704.1429            Light stops in the MSSM parameter space   \n",
       "\n",
       "                                                abstract  Distance  \n",
       "15545    An analysis of inclusive pion production in ...  1.046610  \n",
       "6746     We present pseudorapidity and transverse mom...  1.051520  \n",
       "9537     The increasing size of the data samples reco...  1.055434  \n",
       "7886     We have carried out a calculation of the inc...  1.059579  \n",
       "1984     The cross section for central diffractive Hi...  1.066204  \n",
       "13288    Neutral and charged current deep inelastic s...  1.066468  \n",
       "14716    We consider a highly unconventional approach...  1.097358  \n",
       "9387     An overview of latest top quark pair product...  1.117400  \n",
       "6433     I discuss single top quark production at the...  1.122415  \n",
       "1428     We consider the regions of the MSSM paramete...  1.133265  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search function\n",
    "search_faiss(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad87fce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG\n",
    "def rag_search(query, top_k=3):\n",
    "    # Get documents\n",
    "    docs = search_faiss(query, top_k=top_k)\n",
    "    # Create a prompt for OpenAI\n",
    "    prompt = f\"\"\"\n",
    "    Basándote ÚNICAMENTE en los siguientes documentos relevantes, responde la consulta del usuario.\n",
    "\n",
    "    CONSULTA: \"{query}\"\n",
    "\n",
    "    DOCUMENTOS RELEVANTES:\n",
    "    \"\"\"\n",
    "    \n",
    "    for idx, (_, row) in enumerate(docs.iterrows(), 1):\n",
    "        prompt += f\"\"\"\n",
    "    Documento {idx}:\n",
    "    Título: {row['title']}\n",
    "    Resumen: {row['abstract']}\n",
    "    Distancia semántica: {row['Distance']:.4f}\n",
    "    ---\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt += \"\"\"\n",
    "    INSTRUCCIONES:\n",
    "    1. Resume la información más relevante de estos documentos para responder la consulta\n",
    "    2. Explica por qué estos documentos son relevantes para la consulta\n",
    "    3. Identifica los conceptos clave y metodologías mencionadas\n",
    "    4. Si hay resultados o conclusiones importantes, inclúyelos\n",
    "    5. Mantén un enfoque científico y preciso\n",
    "    \n",
    "    Estructura tu respuesta en:\n",
    "    - Resumen de hallazgos principales\n",
    "    - Relevancia de los documentos\n",
    "    - Conceptos clave identificados\n",
    "    \"\"\"\n",
    "    # Generate response using OpenAI\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4.1\",\n",
    "        input=prompt\n",
    "    )\n",
    "    return response.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb1352c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta de ChatGPT:\n",
      "**Resumen de hallazgos principales:**\n",
      "\n",
      "Ninguno de los documentos relevantes proporciona una medición directa o cálculo explícito de las secciones eficaces (cross sections) de producción de \"diphotons\" (pares de fotones). Sin embargo, los documentos abordan temas relacionados, como la medición de secciones eficaces diferenciales en distintos procesos en colisionadores, la producción de bosones y dibosones (pares de bosones, entre ellos posibles combinaciones de bosones electrodébiles) y la producción de partículas junto a jet en escenarios del Modelo Estándar y MSSM.\n",
      "\n",
      "- El Documento 1 estudia la producción de piones en colisiones protón-berilio a diversas energías y proporciona mediciones detalladas de las secciones eficaces diferenciales para estos procesos.\n",
      "- El Documento 2 aborda la producción del bosón de Higgs neutral más ligero del MSSM asociado con un jet y analiza las distribuciones de secciones eficaces diferenciales (en pseudorapidez y momento transversal) para estos eventos en el LHC y Tevatron.\n",
      "- El Documento 3 revisa mediciones electrodébiles en el Tevatron, incluyendo la observación de producción de pares de bosones (dibosones) como Wγ, Zγ, WW, y WZ, comentando que la producción de pares de bosones ZZ (de los cuales pueden surgir dos fotones en ciertos decaimientos, aunque esto no es equivalente directamente a producción de diphotons) está justo por debajo del umbral de observación con los datos actuales.\n",
      "\n",
      "**Relevancia de los documentos:**\n",
      "\n",
      "Estos documentos no discuten directamente la producción de pares de fotones (diphoton production), pero son relevantes porque:\n",
      "- Proveen contexto sobre cómo se miden y presentan secciones eficaces de producción de estados finales específicos en experimentos de física de altas energías.\n",
      "- Describen metodologías generales y enfoques de análisis para la medición de secciones eficaces diferenciales, que pueden ser aplicables a la producción de diphotons.\n",
      "- El análisis de producción de dibosones electrodébiles y de bosones más un jet es conceptualmente cercano a la producción de diphotons, ya que en física de partículas estas técnicas experimentales y análisis de datos suelen ser compartidos entre los distintos canales de producción.\n",
      "\n",
      "**Conceptos clave identificados:**\n",
      "\n",
      "- **Sección eficaz diferencial**: Expresada como $d^2\\sigma/dpd\\Omega$, describe la probabilidad de producir partículas con ciertos valores de momento y ángulo en una colisión.\n",
      "- **Parámetrizaciones de la sección eficaz**: Por ejemplo, la parametrización de Sanford-Wang utilizada en el Documento 1 para ajustar datos experimentales.\n",
      "- **Producción de bosones (y dibosones) en colisionadores**: En el Documento 3 se mencionan combinaciones de W, Z y fotón (γ), además de discusiones sobre la escala de las secciones eficaces.\n",
      "- **Distribuciones de momento transversal y pseudorapidez**: Análisis detallados de cómo varía la producción de partículas según estas variables, relevantes en la búsqueda y medición de canales específicos como diphotons.\n",
      "- **Modelos teóricos aplicados**: Incluyendo el Modelo Estándar, extensiones como el MSSM, y benchmarks teóricos utilizados para comparar resultados experimentales.\n",
      "\n",
      "**Conclusión:**  \n",
      "Si bien ninguno de los documentos proporciona una medición directa de la sección eficaz de producción de diphotons, describen la metodología y el contexto experimental relevante para este tipo de mediciones en física de altas energías. En particular, destacan cómo se presentan y analizan secciones eficaces diferenciales, la producción de bosones y dibosones, y las técnicas de ajuste y comparación con modelos teóricos.\n"
     ]
    }
   ],
   "source": [
    "response = rag_search(query)\n",
    "print(\"Respuesta de ChatGPT:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bfbd5ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_search_methods(query, top_k=10):\n",
    "    print(f\"=== COMPARACIÓN DE MÉTODOS PARA: '{query}' ===\\n\")\n",
    "    \n",
    "    # 1. Obtener resultados de cada método\n",
    "    tfidf_results = search_tfidf(query)\n",
    "    tfidf_ids = tfidf_results['Identificador'].tolist()\n",
    "        \n",
    "    bm25_results = search_bm25(query)\n",
    "    bm25_ids = bm25_results['Identificador'].tolist()\n",
    "    \n",
    "    faiss_results = search_faiss(query, top_k)\n",
    "    faiss_ids = faiss_results['id'].tolist()\n",
    "\n",
    "    # 2. Análisis de documentos en común (por ID)\n",
    "    print(\"\\n📊 ANÁLISIS DE DOCUMENTOS EN COMÚN (por ID):\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Intersecciones entre métodos usando IDs\n",
    "    tfidf_bm25_common = set(tfidf_ids) & set(bm25_ids)\n",
    "    tfidf_faiss_common = set(tfidf_ids) & set(faiss_ids)\n",
    "    bm25_faiss_common = set(bm25_ids) & set(faiss_ids)\n",
    "    all_common = set(tfidf_ids) & set(bm25_ids) & set(faiss_ids)\n",
    "\n",
    "    print(f\"• TF-IDF ∩ BM25: {len(tfidf_bm25_common)} documentos\")\n",
    "    print(f\"• TF-IDF ∩ FAISS: {len(tfidf_faiss_common)} documentos\")\n",
    "    print(f\"• BM25 ∩ FAISS: {len(bm25_faiss_common)} documentos\")\n",
    "    print(f\"• Común a los 3 métodos: {len(all_common)} documentos\")\n",
    "    \n",
    "    # 3. Mostrar documentos comunes a los 3 métodos\n",
    "    if all_common:\n",
    "        print(f\"\\n🎯 DOCUMENTOS COMUNES A LOS 3 MÉTODOS:\")\n",
    "        print(\"-\" * 80)\n",
    "        for i, doc_id in enumerate(all_common, 1):\n",
    "            # Buscar el documento por ID\n",
    "            doc_info = data[data['id'] == doc_id].iloc[0]\n",
    "            print(f\"{i}. ID: {doc_id}\")\n",
    "            print(f\"   TÍTULO: {doc_info['title']}\")\n",
    "            print(f\"   RESUMEN: {doc_info['abstract'][:150]}...\")\n",
    "            print(f\"   {'='*70}\")\n",
    "    else:\n",
    "        print(\"❌ No hay documentos comunes a los 3 métodos\")\n",
    "    \n",
    "    # 4. Mostrar documentos comunes por pares\n",
    "    print(f\"\\n📋 DOCUMENTOS COMUNES POR PARES:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Solo en TF-IDF y BM25 (no en FAISS)\n",
    "    only_tfidf_bm25 = tfidf_bm25_common - all_common\n",
    "    if only_tfidf_bm25:\n",
    "        print(f\"\\n🔸 Solo en TF-IDF y BM25 ({len(only_tfidf_bm25)} docs):\")\n",
    "        for doc_id in list(only_tfidf_bm25)[:3]:  # Mostrar solo los primeros 3\n",
    "            doc_title = data[data['id'] == doc_id]['title'].iloc[0]\n",
    "            print(f\"   • ID {doc_id}: {doc_title[:60]}...\")\n",
    "    \n",
    "    # Solo en TF-IDF y FAISS (no en BM25)\n",
    "    only_tfidf_faiss = tfidf_faiss_common - all_common\n",
    "    if only_tfidf_faiss:\n",
    "        print(f\"\\n🔸 Solo en TF-IDF y FAISS ({len(only_tfidf_faiss)} docs):\")\n",
    "        for doc_id in list(only_tfidf_faiss)[:3]:\n",
    "            doc_title = data[data['id'] == doc_id]['title'].iloc[0]\n",
    "            print(f\"   • ID {doc_id}: {doc_title[:60]}...\")\n",
    "    \n",
    "    # Solo en BM25 y FAISS (no en TF-IDF)\n",
    "    only_bm25_faiss = bm25_faiss_common - all_common\n",
    "    if only_bm25_faiss:\n",
    "        print(f\"\\n🔸 Solo en BM25 y FAISS ({len(only_bm25_faiss)} docs):\")\n",
    "        for doc_id in list(only_bm25_faiss)[:3]:\n",
    "            doc_title = data[data['id'] == doc_id]['title'].iloc[0]\n",
    "            print(f\"   • ID {doc_id}: {doc_title[:60]}...\")\n",
    "\n",
    "    # 5. Análisis de ordenamiento por ID\n",
    "    print(f\"\\n📈 COMPARACIÓN DE ORDENAMIENTO POR ID:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Crear tabla de comparación con IDs y títulos\n",
    "    comparison_data = []\n",
    "    for pos in range(0, top_k):\n",
    "        row = {'Posición': pos + 1}\n",
    "        \n",
    "        # TF-IDF\n",
    "        if pos < len(tfidf_ids):\n",
    "            tfidf_id = tfidf_ids[pos]\n",
    "            tfidf_title = data[data['id'] == tfidf_id]['title'].iloc[0]\n",
    "            row['TF-IDF'] = f\"ID {tfidf_id}: {tfidf_title[:35]}...\"\n",
    "        else:\n",
    "            row['TF-IDF'] = \"N/A\"\n",
    "            \n",
    "        # BM25\n",
    "        if pos < len(bm25_ids):\n",
    "            bm25_id = bm25_ids[pos]\n",
    "            bm25_title = data[data['id'] == bm25_id]['title'].iloc[0]\n",
    "            row['BM25'] = f\"ID {bm25_id}: {bm25_title[:35]}...\"\n",
    "        else:\n",
    "            row['BM25'] = \"N/A\"\n",
    "            \n",
    "        # FAISS\n",
    "        if pos < len(faiss_ids):\n",
    "            faiss_id = faiss_ids[pos]\n",
    "            faiss_title = data[data['id'] == faiss_id]['title'].iloc[0]\n",
    "            row['FAISS'] = f\"ID {faiss_id}: {faiss_title[:35]}...\"\n",
    "        else:\n",
    "            row['FAISS'] = \"N/A\"\n",
    "            \n",
    "        comparison_data.append(row)\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    \n",
    "    # 6. Métricas de similitud usando IDs\n",
    "    print(f\"\\n📊 MÉTRICAS DE SIMILITUD POR ID:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    def similarity_ids(list1, list2, k=top_k):\n",
    "        set1 = set(list1[:k])\n",
    "        set2 = set(list2[:k])\n",
    "        intersection = len(set1 & set2)\n",
    "        union = len(set1 | set2)\n",
    "        return intersection / union if union > 0 else 0\n",
    "    \n",
    "    tfidf_bm25_sim = similarity_ids(tfidf_ids, bm25_ids)\n",
    "    tfidf_faiss_sim = similarity_ids(tfidf_ids, faiss_ids)\n",
    "    bm25_faiss_sim = similarity_ids(bm25_ids, faiss_ids)\n",
    "    \n",
    "    print(f\"• Similitud TF-IDF vs BM25: {tfidf_bm25_sim:.3f}\")\n",
    "    print(f\"• Similitud TF-IDF vs FAISS: {tfidf_faiss_sim:.3f}\")\n",
    "    print(f\"• Similitud BM25 vs FAISS: {bm25_faiss_sim:.3f}\")\n",
    "    \n",
    "    # 7. Resumen de diferencias\n",
    "    print(f\"\\n📝 RESUMEN DE DIFERENCIAS:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"• TF-IDF: Enfoque estadístico, mejor para coincidencias exactas de términos\")\n",
    "    print(\"• BM25: Mejora de TF-IDF, considera frecuencia de documentos y longitud\")\n",
    "    print(\"• FAISS: Búsqueda semántica, encuentra documentos conceptualmente similares\")\n",
    "    \n",
    "    # 8. Análisis de rendimiento\n",
    "    print(f\"\\n⚡ ANÁLISIS DE RENDIMIENTO:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"• Documentos únicos por método:\")\n",
    "    print(f\"  - Solo TF-IDF: {len(set(tfidf_ids) - set(bm25_ids) - set(faiss_ids))}\")\n",
    "    print(f\"  - Solo BM25: {len(set(bm25_ids) - set(tfidf_ids) - set(faiss_ids))}\")\n",
    "    print(f\"  - Solo FAISS: {len(set(faiss_ids) - set(tfidf_ids) - set(bm25_ids))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6abec479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPARACIÓN DE MÉTODOS PARA: 'diphoton production cross sections' ===\n",
      "\n",
      "\n",
      "📊 ANÁLISIS DE DOCUMENTOS EN COMÚN (por ID):\n",
      "============================================================\n",
      "• TF-IDF ∩ BM25: 0 documentos\n",
      "• TF-IDF ∩ FAISS: 1 documentos\n",
      "• BM25 ∩ FAISS: 0 documentos\n",
      "• Común a los 3 métodos: 0 documentos\n",
      "❌ No hay documentos comunes a los 3 métodos\n",
      "\n",
      "📋 DOCUMENTOS COMUNES POR PARES:\n",
      "------------------------------------------------------------\n",
      "\n",
      "🔸 Solo en TF-IDF y FAISS (1 docs):\n",
      "   • ID 706.0851: Electroweak measurements at the Tevatron...\n",
      "\n",
      "📈 COMPARACIÓN DE ORDENAMIENTO POR ID:\n",
      "================================================================================\n",
      " Posición                                              TF-IDF                                                BM25                                               FAISS\n",
      "        1 ID 704.0001: Calculation of prompt diphoton prod... ID 707.1256: The geometry of the critical set of... ID 707.2375: Pion Production by Protons on a Thi...\n",
      "        2 ID 707.2294: Search for a High-Mass Diphoton Sta... ID 707.0364: Polarization types of isogenous Pry... ID 705.2744: Distributions for MSSM Higgs boson ...\n",
      "        3 ID 706.0851: Electroweak measurements at the Tev... ID 707.1108: Permutation binomials over finite f... ID 706.0851: Electroweak measurements at the Tev...\n",
      "        4 ID 705.4313: Projectile Fragmentation of $^{86}$... ID 705.0325: The order of the largest complete m... ID 705.3884: Inclusive electron spectrum in the ...\n",
      "        5 ID 706.2813: Measurement of the Total Hadronic C... ID 706.4102: Ramsey numbers and the size of grap...    ID 704.1985: Electromagnetic Higgs production...\n",
      "        6 ID 706.2117: Novel Master Formula for Twist-3 So... ID 707.3316: Morita equivalences of cyclotomic H... ID 707.0118: Proton Structure Functions at High ...\n",
      "        7 ID 705.0349: New isotope 44Si and systematics of...  ID 705.3749: Difference sets and shifted primes... ID 707.1546: Producing an Intense, Cool Muon Bea...\n",
      "        8 ID 706.2693: Reaction cross sections for proton ... ID 707.1102: Nonexistence of permutation binomia... ID 706.0701: Top Pair Production cross-section a...\n",
      "        9 ID 705.4249: Extrapolation of neutron-rich isoto...      ID 707.2612: Exceptional covers of surfaces... ID 705.2431: Higher-order Threshold Corrections ...\n",
      "       10 ID 705.1051: Quasi-elastic neutrino charged-curr... ID 707.3672: Products of irreducible random matr... ID 704.1429: Light stops in the MSSM parameter s...\n",
      "\n",
      "📊 MÉTRICAS DE SIMILITUD POR ID:\n",
      "--------------------------------------------------\n",
      "• Similitud TF-IDF vs BM25: 0.000\n",
      "• Similitud TF-IDF vs FAISS: 0.053\n",
      "• Similitud BM25 vs FAISS: 0.000\n",
      "\n",
      "📝 RESUMEN DE DIFERENCIAS:\n",
      "==================================================\n",
      "• TF-IDF: Enfoque estadístico, mejor para coincidencias exactas de términos\n",
      "• BM25: Mejora de TF-IDF, considera frecuencia de documentos y longitud\n",
      "• FAISS: Búsqueda semántica, encuentra documentos conceptualmente similares\n",
      "\n",
      "⚡ ANÁLISIS DE RENDIMIENTO:\n",
      "--------------------------------------------------\n",
      "• Documentos únicos por método:\n",
      "  - Solo TF-IDF: 9\n",
      "  - Solo BM25: 10\n",
      "  - Solo FAISS: 9\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar comparación\n",
    "comparison_results = compare_search_methods(query, top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a41027a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_ranking_overlap(query, top_k=10):\n",
    "    \"\"\"\n",
    "    Mide similitud entre rankings contando cuántos documentos del top-k coinciden\n",
    "    \"\"\"\n",
    "    print(f\"=== SIMILITUD ENTRE RANKINGS (Top-{top_k}) ===\")\n",
    "    print(f\"Consulta: '{query}'\\n\")\n",
    "    \n",
    "    # 1. Obtener resultados de cada método\n",
    "    tfidf_results = search_tfidf(query, top_k)\n",
    "    tfidf_ids = set(tfidf_results['Identificador'].tolist())\n",
    "    \n",
    "    bm25_results = search_bm25(query, top_k)\n",
    "    bm25_ids = set(bm25_results['Identificador'].tolist())\n",
    "    \n",
    "    faiss_results = search_faiss(query, top_k)\n",
    "    faiss_ids = set(faiss_results['id'].tolist())\n",
    "    \n",
    "    # 2. Contar documentos coincidentes\n",
    "    print(\"📊 DOCUMENTOS COINCIDENTES:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Intersecciones entre pares\n",
    "    tfidf_bm25_overlap = len(tfidf_ids & bm25_ids)\n",
    "    tfidf_faiss_overlap = len(tfidf_ids & faiss_ids)\n",
    "    bm25_faiss_overlap = len(bm25_ids & faiss_ids)\n",
    "    \n",
    "    # Intersección de los tres métodos\n",
    "    all_three_overlap = len(tfidf_ids & bm25_ids & faiss_ids)\n",
    "    \n",
    "    print(f\"TF-IDF ∩ BM25:     {tfidf_bm25_overlap}/{top_k} documentos ({tfidf_bm25_overlap/top_k*100:.1f}%)\")\n",
    "    print(f\"TF-IDF ∩ FAISS:    {tfidf_faiss_overlap}/{top_k} documentos ({tfidf_faiss_overlap/top_k*100:.1f}%)\")\n",
    "    print(f\"BM25 ∩ FAISS:      {bm25_faiss_overlap}/{top_k} documentos ({bm25_faiss_overlap/top_k*100:.1f}%)\")\n",
    "    print(f\"Común a los 3:     {all_three_overlap}/{top_k} documentos ({all_three_overlap/top_k*100:.1f}%)\")\n",
    "    \n",
    "    # 3. Calcular similitud normalizada (0-1)\n",
    "    print(f\"\\n📈 SIMILITUD NORMALIZADA:\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    sim_tfidf_bm25 = tfidf_bm25_overlap / top_k\n",
    "    sim_tfidf_faiss = tfidf_faiss_overlap / top_k\n",
    "    sim_bm25_faiss = bm25_faiss_overlap / top_k\n",
    "    sim_all_three = all_three_overlap / top_k\n",
    "    \n",
    "    print(f\"TF-IDF vs BM25:    {sim_tfidf_bm25:.3f}\")\n",
    "    print(f\"TF-IDF vs FAISS:   {sim_tfidf_faiss:.3f}\")\n",
    "    print(f\"BM25 vs FAISS:     {sim_bm25_faiss:.3f}\")\n",
    "    print(f\"Consenso (3 métodos): {sim_all_three:.3f}\")\n",
    "    \n",
    "    # 4. Similitud promedio\n",
    "    avg_similarity = (sim_tfidf_bm25 + sim_tfidf_faiss + sim_bm25_faiss) / 3\n",
    "    print(f\"\\nSimilitud promedio: {avg_similarity:.3f}\")\n",
    "    \n",
    "    # 5. Interpretación\n",
    "    if avg_similarity >= 0.7:\n",
    "        interpretation = \"MUY ALTA similitud - Los métodos coinciden mucho\"\n",
    "    elif avg_similarity >= 0.5:\n",
    "        interpretation = \"ALTA similitud - Buen consenso entre métodos\"\n",
    "    elif avg_similarity >= 0.3:\n",
    "        interpretation = \"MEDIA similitud - Consenso moderado\"\n",
    "    else:\n",
    "        interpretation = \"BAJA similitud - Los métodos difieren significativamente\"\n",
    "    \n",
    "    print(f\"Interpretación: {interpretation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "48d9c217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SIMILITUD ENTRE RANKINGS (Top-10) ===\n",
      "Consulta: 'diphoton production cross sections'\n",
      "\n",
      "📊 DOCUMENTOS COINCIDENTES:\n",
      "========================================\n",
      "TF-IDF ∩ BM25:     0/10 documentos (0.0%)\n",
      "TF-IDF ∩ FAISS:    1/10 documentos (10.0%)\n",
      "BM25 ∩ FAISS:      0/10 documentos (0.0%)\n",
      "Común a los 3:     0/10 documentos (0.0%)\n",
      "\n",
      "📈 SIMILITUD NORMALIZADA:\n",
      "==============================\n",
      "TF-IDF vs BM25:    0.000\n",
      "TF-IDF vs FAISS:   0.100\n",
      "BM25 vs FAISS:     0.000\n",
      "Consenso (3 métodos): 0.000\n",
      "\n",
      "Similitud promedio: 0.033\n",
      "Interpretación: BAJA similitud - Los métodos difieren significativamente\n"
     ]
    }
   ],
   "source": [
    "overlap_results = measure_ranking_overlap(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
