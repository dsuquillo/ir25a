{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45fdbbc5",
   "metadata": {},
   "source": [
    "Examen Bimestral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c88a6713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "import json\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0c45620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo JSON\n",
    "url = '../data/arxiv_examen.json'\n",
    "data = pd.read_json(url, encoding='utf-8', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1741980f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/murder/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/murder/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/murder/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Descargar recursos necesarios de nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa743c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id                                              title  \\\n",
      "0      704.0001  Calculation of prompt diphoton production cros...   \n",
      "1      704.0002           Sparsity-certifying Graph Decompositions   \n",
      "2      704.0003  The evolution of the Earth-Moon system based o...   \n",
      "3      704.0004  A determinant of Stirling cycle numbers counts...   \n",
      "4      704.0005  From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...   \n",
      "...         ...                                                ...   \n",
      "16995  707.3825  Emergence of noncollinear magnetic ordering in...   \n",
      "16996  707.3826                      More hilltop inflation models   \n",
      "16997  707.3827  Engineering Silicon Nanocrystals: Theoretical ...   \n",
      "16998  707.3828  Structure, bonding and magnetism in cobalt clu...   \n",
      "16999  707.3829  Occupation Statistics of Critical Branching Ra...   \n",
      "\n",
      "                                                abstract  \n",
      "0        A fully differential calculation in perturba...  \n",
      "1        We describe a new algorithm, the $(k,\\ell)$-...  \n",
      "2        The evolution of Earth-Moon system is descri...  \n",
      "3        We show that a determinant of Stirling cycle...  \n",
      "4        In this paper we show how to compute the $\\L...  \n",
      "...                                                  ...  \n",
      "16995    Using first-principles density functional ca...  \n",
      "16996    Using analytic expressions, we explore the p...  \n",
      "16997    We show that the optical and electronic prop...  \n",
      "16998    The structural, electronic and magnetic prop...  \n",
      "16999    Consider a critical nearest neighbor branchi...  \n",
      "\n",
      "[17000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60edd661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            title_tokens  \\\n",
      "0      [calculation, prompt, diphoton, production, cr...   \n",
      "1           [sparsity-certifying, graph, decompositions]   \n",
      "2      [evolution, earth-moon, system, based, dark, m...   \n",
      "3      [determinant, stirling, cycle, numbers, counts...   \n",
      "4           [dyadic, \\lambda_, \\alpha, \\lambda_, \\alpha]   \n",
      "...                                                  ...   \n",
      "16995  [emergence, noncollinear, magnetic, ordering, ...   \n",
      "16996                       [hilltop, inflation, models]   \n",
      "16997  [engineering, silicon, nanocrystals, theoretic...   \n",
      "16998  [structure, bonding, magnetism, cobalt, clusters]   \n",
      "16999  [occupation, statistics, critical, branching, ...   \n",
      "\n",
      "                                         abstract_tokens  \n",
      "0      [fully, differential, calculation, perturbativ...  \n",
      "1      [describe, new, algorithm, k, \\ell, -pebble, g...  \n",
      "2      [evolution, earth-moon, system, described, dar...  \n",
      "3      [show, determinant, stirling, cycle, numbers, ...  \n",
      "4      [paper, show, compute, \\lambda_, \\alpha, norm,...  \n",
      "...                                                  ...  \n",
      "16995  [using, first-principles, density, functional,...  \n",
      "16996  [using, analytic, expressions, explore, parame...  \n",
      "16997  [show, optical, electronic, properties, nanocr...  \n",
      "16998  [structural, electronic, magnetic, properties,...  \n",
      "16999  [consider, critical, nearest, neighbor, branch...  \n",
      "\n",
      "[17000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Definir stopwords en inglés\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Función para preprocesar texto\n",
    "def preprocess_text(text):\n",
    "    # Convertir a minúsculas\n",
    "    text = text.lower()\n",
    "    # Tokenizar palabras\n",
    "    tokens = word_tokenize(text)\n",
    "    # Eliminar stopwords y signos de puntuación\n",
    "    tokens = [word for word in tokens if word not in stop_words and word not in string.punctuation]\n",
    "    return tokens\n",
    "\n",
    "# Aplicar función al título y resumen\n",
    "data['title_tokens'] = data['title'].apply(preprocess_text)\n",
    "data['abstract_tokens'] = data['abstract'].apply(preprocess_text)\n",
    "\n",
    "# Mostrar resultado\n",
    "print(data[['title_tokens', 'abstract_tokens']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33c67f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17000, 44149)\n"
     ]
    }
   ],
   "source": [
    "# Vectorizar\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "# Fit on the combined text from title_tokens and abstract_tokens\n",
    "vectorizer.fit(data['title_tokens'].astype(str) + ' ' + data['abstract_tokens'].astype(str))\n",
    "corpus_vect = vectorizer.transform(data['title_tokens'].astype(str) + ' ' + data['abstract_tokens'].astype(str)) # Transformación\n",
    "print(corpus_vect.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "849fd1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a853f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para buscar usando TF-IDF\n",
    "def search_tfidf(query, vectorizer, corpus_vect, data,  top_k=10):\n",
    "    # Vectorize the query\n",
    "    query_vect = vectorizer.transform([query])\n",
    "\n",
    "    # Calculate cosine similarities between the query and documents\n",
    "    cosine_similarities = cosine_similarity(query_vect, corpus_vect).flatten()\n",
    "\n",
    "    # Create a DataFrame with the results\n",
    "    df_results = pd.DataFrame({'Documento': data['abstract'], 'Similitud coseno': cosine_similarities})\n",
    "\n",
    "    # Sort by similarity and get the top results\n",
    "    df_results = df_results.sort_values(by='Similitud coseno', ascending=False)\n",
    "    return df_results.head(top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c85146ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"diphoton production cross sections\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bed3defc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Documento</th>\n",
       "      <th>Similitud coseno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A fully differential calculation in perturba...</td>\n",
       "      <td>0.393993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15464</th>\n",
       "      <td>We have performed a search for new particles...</td>\n",
       "      <td>0.362845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9537</th>\n",
       "      <td>The increasing size of the data samples reco...</td>\n",
       "      <td>0.332994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8315</th>\n",
       "      <td>We measured fragmentation cross sections pro...</td>\n",
       "      <td>0.306359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11499</th>\n",
       "      <td>Using the CLEO III detector, we measure abso...</td>\n",
       "      <td>0.285362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10803</th>\n",
       "      <td>We prove that twist-3 soft-gluon-pole (SGP) ...</td>\n",
       "      <td>0.264567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4351</th>\n",
       "      <td>The results of measurements of the productio...</td>\n",
       "      <td>0.257428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11379</th>\n",
       "      <td>Microscopic optical model potential results ...</td>\n",
       "      <td>0.252194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8251</th>\n",
       "      <td>Using the measured fragmentation cross secti...</td>\n",
       "      <td>0.251028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5053</th>\n",
       "      <td>The charged-current quasi-elastic scattering...</td>\n",
       "      <td>0.245088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Documento  Similitud coseno\n",
       "0        A fully differential calculation in perturba...          0.393993\n",
       "15464    We have performed a search for new particles...          0.362845\n",
       "9537     The increasing size of the data samples reco...          0.332994\n",
       "8315     We measured fragmentation cross sections pro...          0.306359\n",
       "11499    Using the CLEO III detector, we measure abso...          0.285362\n",
       "10803    We prove that twist-3 soft-gluon-pole (SGP) ...          0.264567\n",
       "4351     The results of measurements of the productio...          0.257428\n",
       "11379    Microscopic optical model potential results ...          0.252194\n",
       "8251     Using the measured fragmentation cross secti...          0.251028\n",
       "5053     The charged-current quasi-elastic scattering...          0.245088"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_tfidf(query, vectorizer, corpus_vect, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b6ac49f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25 Search\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "def search_bm25(query,  top_k=10):\n",
    "  # Tokenize the corpus for BM25\n",
    "  tokenized_corpus = data['abstract_tokens'].tolist()\n",
    "\n",
    "  bm25_doc = BM25Okapi(tokenized_corpus)\n",
    "  scores = bm25_doc.get_scores(query)\n",
    "\n",
    "  # Create a DataFrame with the data\n",
    "  df = pd.DataFrame({'Documento': data['abstract'], 'Score BM25': scores})\n",
    "  df = df.sort_values(by='Score BM25', ascending=False)\n",
    "  bm25_results = df.head(top_k)\n",
    "  bm25_results\n",
    "  return bm25_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "898ad66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Documento</th>\n",
       "      <th>Score BM25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14426</th>\n",
       "      <td>We study the critical set C of the nonlinear...</td>\n",
       "      <td>54.005663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13534</th>\n",
       "      <td>Let p:C--&gt;Y be a covering of smooth, project...</td>\n",
       "      <td>49.654692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14278</th>\n",
       "      <td>We prove that if x^m + c*x^n permutes the pr...</td>\n",
       "      <td>46.431785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4327</th>\n",
       "      <td>Let ccl(G) denote the order of the largest c...</td>\n",
       "      <td>43.879518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12788</th>\n",
       "      <td>For two graph H and G, the Ramsey number r(H...</td>\n",
       "      <td>43.550299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16486</th>\n",
       "      <td>We prove a Morita reduction theorem for the ...</td>\n",
       "      <td>43.228933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7751</th>\n",
       "      <td>We show that if A is a subset of {1, ..., n}...</td>\n",
       "      <td>42.580936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14272</th>\n",
       "      <td>Suppose x^m + c*x^n is a permutation polynom...</td>\n",
       "      <td>41.792553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15782</th>\n",
       "      <td>Consider a finite morphism f:X -&gt; Y of smoot...</td>\n",
       "      <td>39.846724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16842</th>\n",
       "      <td>We consider the recursive equation ``x(n+1)=...</td>\n",
       "      <td>39.735954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Documento  Score BM25\n",
       "14426    We study the critical set C of the nonlinear...   54.005663\n",
       "13534    Let p:C-->Y be a covering of smooth, project...   49.654692\n",
       "14278    We prove that if x^m + c*x^n permutes the pr...   46.431785\n",
       "4327     Let ccl(G) denote the order of the largest c...   43.879518\n",
       "12788    For two graph H and G, the Ramsey number r(H...   43.550299\n",
       "16486    We prove a Morita reduction theorem for the ...   43.228933\n",
       "7751     We show that if A is a subset of {1, ..., n}...   42.580936\n",
       "14272    Suppose x^m + c*x^n is a permutation polynom...   41.792553\n",
       "15782    Consider a finite morphism f:X -> Y of smoot...   39.846724\n",
       "16842    We consider the recursive equation ``x(n+1)=...   39.735954"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_bm25(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e965d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
