{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45fdbbc5",
   "metadata": {},
   "source": [
    "Examen Bimestral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88a6713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0c45620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo JSON\n",
    "url = '../data/arxiv_examen.json'\n",
    "data = pd.read_json(url, encoding='utf-8', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1741980f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/murder/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/murder/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/murder/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Descargar recursos necesarios de nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa743c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id                                              title  \\\n",
      "0      704.0001  Calculation of prompt diphoton production cros...   \n",
      "1      704.0002           Sparsity-certifying Graph Decompositions   \n",
      "2      704.0003  The evolution of the Earth-Moon system based o...   \n",
      "3      704.0004  A determinant of Stirling cycle numbers counts...   \n",
      "4      704.0005  From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...   \n",
      "...         ...                                                ...   \n",
      "16995  707.3825  Emergence of noncollinear magnetic ordering in...   \n",
      "16996  707.3826                      More hilltop inflation models   \n",
      "16997  707.3827  Engineering Silicon Nanocrystals: Theoretical ...   \n",
      "16998  707.3828  Structure, bonding and magnetism in cobalt clu...   \n",
      "16999  707.3829  Occupation Statistics of Critical Branching Ra...   \n",
      "\n",
      "                                                abstract  \n",
      "0        A fully differential calculation in perturba...  \n",
      "1        We describe a new algorithm, the $(k,\\ell)$-...  \n",
      "2        The evolution of Earth-Moon system is descri...  \n",
      "3        We show that a determinant of Stirling cycle...  \n",
      "4        In this paper we show how to compute the $\\L...  \n",
      "...                                                  ...  \n",
      "16995    Using first-principles density functional ca...  \n",
      "16996    Using analytic expressions, we explore the p...  \n",
      "16997    We show that the optical and electronic prop...  \n",
      "16998    The structural, electronic and magnetic prop...  \n",
      "16999    Consider a critical nearest neighbor branchi...  \n",
      "\n",
      "[17000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60edd661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            title_tokens  \\\n",
      "0      [calculation, prompt, diphoton, production, cr...   \n",
      "1           [sparsity-certifying, graph, decompositions]   \n",
      "2      [evolution, earth-moon, system, based, dark, m...   \n",
      "3      [determinant, stirling, cycle, numbers, counts...   \n",
      "4           [dyadic, \\lambda_, \\alpha, \\lambda_, \\alpha]   \n",
      "...                                                  ...   \n",
      "16995  [emergence, noncollinear, magnetic, ordering, ...   \n",
      "16996                       [hilltop, inflation, models]   \n",
      "16997  [engineering, silicon, nanocrystals, theoretic...   \n",
      "16998  [structure, bonding, magnetism, cobalt, clusters]   \n",
      "16999  [occupation, statistics, critical, branching, ...   \n",
      "\n",
      "                                         abstract_tokens  \n",
      "0      [fully, differential, calculation, perturbativ...  \n",
      "1      [describe, new, algorithm, k, \\ell, -pebble, g...  \n",
      "2      [evolution, earth-moon, system, described, dar...  \n",
      "3      [show, determinant, stirling, cycle, numbers, ...  \n",
      "4      [paper, show, compute, \\lambda_, \\alpha, norm,...  \n",
      "...                                                  ...  \n",
      "16995  [using, first-principles, density, functional,...  \n",
      "16996  [using, analytic, expressions, explore, parame...  \n",
      "16997  [show, optical, electronic, properties, nanocr...  \n",
      "16998  [structural, electronic, magnetic, properties,...  \n",
      "16999  [consider, critical, nearest, neighbor, branch...  \n",
      "\n",
      "[17000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Definir stopwords en ingl√©s\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Funci√≥n para preprocesar texto\n",
    "def preprocess_text(text):\n",
    "    # Convertir a min√∫sculas\n",
    "    text = text.lower()\n",
    "    # Tokenizar palabras\n",
    "    tokens = word_tokenize(text)\n",
    "    # Eliminar stopwords y signos de puntuaci√≥n\n",
    "    tokens = [word for word in tokens if word not in stop_words and word not in string.punctuation]\n",
    "    return tokens\n",
    "\n",
    "# Aplicar funci√≥n al t√≠tulo y resumen\n",
    "data['title_tokens'] = data['title'].apply(preprocess_text)\n",
    "data['abstract_tokens'] = data['abstract'].apply(preprocess_text)\n",
    "\n",
    "# Mostrar resultado\n",
    "print(data[['title_tokens', 'abstract_tokens']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33c67f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17000, 44149)\n"
     ]
    }
   ],
   "source": [
    "# Vectorizar\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "# Fit on the combined text from title_tokens and abstract_tokens\n",
    "vectorizer.fit(data['title_tokens'].astype(str) + ' ' + data['abstract_tokens'].astype(str))\n",
    "corpus_vect = vectorizer.transform(data['title_tokens'].astype(str) + ' ' + data['abstract_tokens'].astype(str)) # Transformaci√≥n\n",
    "print(corpus_vect.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "849fd1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3a853f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para buscar usando TF-IDF\n",
    "def search_tfidf(query, top_k=10):\n",
    "    # Vectorize the query\n",
    "    query_vect = vectorizer.transform([query])\n",
    "\n",
    "    # Calculate cosine similarities between the query and documents\n",
    "    cosine_similarities = cosine_similarity(query_vect, corpus_vect).flatten()\n",
    "\n",
    "    # Create a DataFrame with the results\n",
    "    df_results = pd.DataFrame({'Identificador': data['id'], 'T√≠tulo': data['title'], 'Resumen': data['abstract'], 'Similitud coseno': cosine_similarities})\n",
    "\n",
    "    # Sort by similarity and get the top results\n",
    "    df_results = df_results.sort_values(by='Similitud coseno', ascending=False)\n",
    "    return df_results.head(top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c85146ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"diphoton production cross sections\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bed3defc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identificador</th>\n",
       "      <th>T√≠tulo</th>\n",
       "      <th>Resumen</th>\n",
       "      <th>Similitud coseno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>704.0001</td>\n",
       "      <td>Calculation of prompt diphoton production cros...</td>\n",
       "      <td>A fully differential calculation in perturba...</td>\n",
       "      <td>0.393993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15464</th>\n",
       "      <td>707.2294</td>\n",
       "      <td>Search for a High-Mass Diphoton State and Limi...</td>\n",
       "      <td>We have performed a search for new particles...</td>\n",
       "      <td>0.362845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9537</th>\n",
       "      <td>706.0851</td>\n",
       "      <td>Electroweak measurements at the Tevatron</td>\n",
       "      <td>The increasing size of the data samples reco...</td>\n",
       "      <td>0.332994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8315</th>\n",
       "      <td>705.4313</td>\n",
       "      <td>Projectile Fragmentation of $^{86}$Kr at 64 Me...</td>\n",
       "      <td>We measured fragmentation cross sections pro...</td>\n",
       "      <td>0.306359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11499</th>\n",
       "      <td>706.2813</td>\n",
       "      <td>Measurement of the Total Hadronic Cross Sectio...</td>\n",
       "      <td>Using the CLEO III detector, we measure abso...</td>\n",
       "      <td>0.285362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10803</th>\n",
       "      <td>706.2117</td>\n",
       "      <td>Novel Master Formula for Twist-3 Soft-Gluon-Po...</td>\n",
       "      <td>We prove that twist-3 soft-gluon-pole (SGP) ...</td>\n",
       "      <td>0.264567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4351</th>\n",
       "      <td>705.0349</td>\n",
       "      <td>New isotope 44Si and systematics of the produc...</td>\n",
       "      <td>The results of measurements of the productio...</td>\n",
       "      <td>0.257428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11379</th>\n",
       "      <td>706.2693</td>\n",
       "      <td>Reaction cross sections for proton scattering ...</td>\n",
       "      <td>Microscopic optical model potential results ...</td>\n",
       "      <td>0.252194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8251</th>\n",
       "      <td>705.4249</td>\n",
       "      <td>Extrapolation of neutron-rich isotope cross-se...</td>\n",
       "      <td>Using the measured fragmentation cross secti...</td>\n",
       "      <td>0.251028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5053</th>\n",
       "      <td>705.1051</td>\n",
       "      <td>Quasi-elastic neutrino charged-current scatter...</td>\n",
       "      <td>The charged-current quasi-elastic scattering...</td>\n",
       "      <td>0.245088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Identificador                                             T√≠tulo  \\\n",
       "0           704.0001  Calculation of prompt diphoton production cros...   \n",
       "15464       707.2294  Search for a High-Mass Diphoton State and Limi...   \n",
       "9537        706.0851           Electroweak measurements at the Tevatron   \n",
       "8315        705.4313  Projectile Fragmentation of $^{86}$Kr at 64 Me...   \n",
       "11499       706.2813  Measurement of the Total Hadronic Cross Sectio...   \n",
       "10803       706.2117  Novel Master Formula for Twist-3 Soft-Gluon-Po...   \n",
       "4351        705.0349  New isotope 44Si and systematics of the produc...   \n",
       "11379       706.2693  Reaction cross sections for proton scattering ...   \n",
       "8251        705.4249  Extrapolation of neutron-rich isotope cross-se...   \n",
       "5053        705.1051  Quasi-elastic neutrino charged-current scatter...   \n",
       "\n",
       "                                                 Resumen  Similitud coseno  \n",
       "0        A fully differential calculation in perturba...          0.393993  \n",
       "15464    We have performed a search for new particles...          0.362845  \n",
       "9537     The increasing size of the data samples reco...          0.332994  \n",
       "8315     We measured fragmentation cross sections pro...          0.306359  \n",
       "11499    Using the CLEO III detector, we measure abso...          0.285362  \n",
       "10803    We prove that twist-3 soft-gluon-pole (SGP) ...          0.264567  \n",
       "4351     The results of measurements of the productio...          0.257428  \n",
       "11379    Microscopic optical model potential results ...          0.252194  \n",
       "8251     Using the measured fragmentation cross secti...          0.251028  \n",
       "5053     The charged-current quasi-elastic scattering...          0.245088  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_tfidf(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b6ac49f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25 Search\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "def search_bm25(query,  top_k=10):\n",
    "  # Tokenize the corpus for BM25\n",
    "  tokenized_corpus = data['abstract_tokens'].tolist()\n",
    "\n",
    "  bm25_doc = BM25Okapi(tokenized_corpus)\n",
    "  scores = bm25_doc.get_scores(query)\n",
    "\n",
    "  # Create a DataFrame with the data\n",
    "  df = pd.DataFrame({'Identificador': data['id'], 'T√≠tulo': data['title'], 'Resumen': data['abstract'], 'Score BM25': scores})\n",
    "  df = df.sort_values(by='Score BM25', ascending=False)\n",
    "  bm25_results = df.head(top_k)\n",
    "  bm25_results\n",
    "  return bm25_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "898ad66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identificador</th>\n",
       "      <th>T√≠tulo</th>\n",
       "      <th>Resumen</th>\n",
       "      <th>Score BM25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14426</th>\n",
       "      <td>707.1256</td>\n",
       "      <td>The geometry of the critical set of nonlinear ...</td>\n",
       "      <td>We study the critical set C of the nonlinear...</td>\n",
       "      <td>54.005663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13534</th>\n",
       "      <td>707.0364</td>\n",
       "      <td>Polarization types of isogenous Prym-Tyurin va...</td>\n",
       "      <td>Let p:C--&gt;Y be a covering of smooth, project...</td>\n",
       "      <td>49.654692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14278</th>\n",
       "      <td>707.1108</td>\n",
       "      <td>Permutation binomials over finite fields</td>\n",
       "      <td>We prove that if x^m + c*x^n permutes the pr...</td>\n",
       "      <td>46.431785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4327</th>\n",
       "      <td>705.0325</td>\n",
       "      <td>The order of the largest complete minor in a r...</td>\n",
       "      <td>Let ccl(G) denote the order of the largest c...</td>\n",
       "      <td>43.879518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12788</th>\n",
       "      <td>706.4102</td>\n",
       "      <td>Ramsey numbers and the size of graphs</td>\n",
       "      <td>For two graph H and G, the Ramsey number r(H...</td>\n",
       "      <td>43.550299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16486</th>\n",
       "      <td>707.3316</td>\n",
       "      <td>Morita equivalences of cyclotomic Hecke algebr...</td>\n",
       "      <td>We prove a Morita reduction theorem for the ...</td>\n",
       "      <td>43.228933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7751</th>\n",
       "      <td>705.3749</td>\n",
       "      <td>Difference sets and shifted primes</td>\n",
       "      <td>We show that if A is a subset of {1, ..., n}...</td>\n",
       "      <td>42.580936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14272</th>\n",
       "      <td>707.1102</td>\n",
       "      <td>Nonexistence of permutation binomials of certa...</td>\n",
       "      <td>Suppose x^m + c*x^n is a permutation polynom...</td>\n",
       "      <td>41.792553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15782</th>\n",
       "      <td>707.2612</td>\n",
       "      <td>Exceptional covers of surfaces</td>\n",
       "      <td>Consider a finite morphism f:X -&gt; Y of smoot...</td>\n",
       "      <td>39.846724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16842</th>\n",
       "      <td>707.3672</td>\n",
       "      <td>Products of irreducible random matrices in the...</td>\n",
       "      <td>We consider the recursive equation ``x(n+1)=...</td>\n",
       "      <td>39.735954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Identificador                                             T√≠tulo  \\\n",
       "14426       707.1256  The geometry of the critical set of nonlinear ...   \n",
       "13534       707.0364  Polarization types of isogenous Prym-Tyurin va...   \n",
       "14278       707.1108           Permutation binomials over finite fields   \n",
       "4327        705.0325  The order of the largest complete minor in a r...   \n",
       "12788       706.4102              Ramsey numbers and the size of graphs   \n",
       "16486       707.3316  Morita equivalences of cyclotomic Hecke algebr...   \n",
       "7751        705.3749                 Difference sets and shifted primes   \n",
       "14272       707.1102  Nonexistence of permutation binomials of certa...   \n",
       "15782       707.2612                     Exceptional covers of surfaces   \n",
       "16842       707.3672  Products of irreducible random matrices in the...   \n",
       "\n",
       "                                                 Resumen  Score BM25  \n",
       "14426    We study the critical set C of the nonlinear...   54.005663  \n",
       "13534    Let p:C-->Y be a covering of smooth, project...   49.654692  \n",
       "14278    We prove that if x^m + c*x^n permutes the pr...   46.431785  \n",
       "4327     Let ccl(G) denote the order of the largest c...   43.879518  \n",
       "12788    For two graph H and G, the Ramsey number r(H...   43.550299  \n",
       "16486    We prove a Morita reduction theorem for the ...   43.228933  \n",
       "7751     We show that if A is a subset of {1, ..., n}...   42.580936  \n",
       "14272    Suppose x^m + c*x^n is a permutation polynom...   41.792553  \n",
       "15782    Consider a finite morphism f:X -> Y of smoot...   39.846724  \n",
       "16842    We consider the recursive equation ``x(n+1)=...   39.735954  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_bm25(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e965d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d405f121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando embeddings...\n"
     ]
    }
   ],
   "source": [
    "# Create embeddings for the recipes data\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"Generando embeddings...\")\n",
    "embeddings = model.encode(data['abstract'].tolist(), convert_to_numpy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d30bfe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create index FAISS\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])  # L2 distance\n",
    "index.add(embeddings)  # Add embeddings to the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47edbf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config OpenAI\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fd2eac76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search function\n",
    "def search_faiss(query, top_k=10):\n",
    "    # Create embedding for the query\n",
    "    query_embedding = model.encode([query], convert_to_numpy=True)\n",
    "\n",
    "    # Search in the index\n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "\n",
    "    # Get the results from the original data\n",
    "    results = data.iloc[indices[0]].copy()\n",
    "    results['Distance'] = distances[0]\n",
    "    \n",
    "    return results[['id', 'title', 'abstract', 'Distance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "66b9a07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15545</th>\n",
       "      <td>707.2375</td>\n",
       "      <td>Pion Production by Protons on a Thin Beryllium...</td>\n",
       "      <td>An analysis of inclusive pion production in ...</td>\n",
       "      <td>1.046610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6746</th>\n",
       "      <td>705.2744</td>\n",
       "      <td>Distributions for MSSM Higgs boson + jet produ...</td>\n",
       "      <td>We present pseudorapidity and transverse mom...</td>\n",
       "      <td>1.051520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9537</th>\n",
       "      <td>706.0851</td>\n",
       "      <td>Electroweak measurements at the Tevatron</td>\n",
       "      <td>The increasing size of the data samples reco...</td>\n",
       "      <td>1.055434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7886</th>\n",
       "      <td>705.3884</td>\n",
       "      <td>Inclusive electron spectrum in the region of p...</td>\n",
       "      <td>We have carried out a calculation of the inc...</td>\n",
       "      <td>1.059579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>704.1985</td>\n",
       "      <td>Electromagnetic Higgs production</td>\n",
       "      <td>The cross section for central diffractive Hi...</td>\n",
       "      <td>1.066204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13288</th>\n",
       "      <td>707.0118</td>\n",
       "      <td>Proton Structure Functions at High $Q^{2}$ and...</td>\n",
       "      <td>Neutral and charged current deep inelastic s...</td>\n",
       "      <td>1.066468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14716</th>\n",
       "      <td>707.1546</td>\n",
       "      <td>Producing an Intense, Cool Muon Beam via e+e- ...</td>\n",
       "      <td>We consider a highly unconventional approach...</td>\n",
       "      <td>1.097358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9387</th>\n",
       "      <td>706.0701</td>\n",
       "      <td>Top Pair Production cross-section at the Tevatron</td>\n",
       "      <td>An overview of latest top quark pair product...</td>\n",
       "      <td>1.117400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6433</th>\n",
       "      <td>705.2431</td>\n",
       "      <td>Higher-order Threshold Corrections for Single ...</td>\n",
       "      <td>I discuss single top quark production at the...</td>\n",
       "      <td>1.122415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>704.1429</td>\n",
       "      <td>Light stops in the MSSM parameter space</td>\n",
       "      <td>We consider the regions of the MSSM paramete...</td>\n",
       "      <td>1.133265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                              title  \\\n",
       "15545  707.2375  Pion Production by Protons on a Thin Beryllium...   \n",
       "6746   705.2744  Distributions for MSSM Higgs boson + jet produ...   \n",
       "9537   706.0851           Electroweak measurements at the Tevatron   \n",
       "7886   705.3884  Inclusive electron spectrum in the region of p...   \n",
       "1984   704.1985                   Electromagnetic Higgs production   \n",
       "13288  707.0118  Proton Structure Functions at High $Q^{2}$ and...   \n",
       "14716  707.1546  Producing an Intense, Cool Muon Beam via e+e- ...   \n",
       "9387   706.0701  Top Pair Production cross-section at the Tevatron   \n",
       "6433   705.2431  Higher-order Threshold Corrections for Single ...   \n",
       "1428   704.1429            Light stops in the MSSM parameter space   \n",
       "\n",
       "                                                abstract  Distance  \n",
       "15545    An analysis of inclusive pion production in ...  1.046610  \n",
       "6746     We present pseudorapidity and transverse mom...  1.051520  \n",
       "9537     The increasing size of the data samples reco...  1.055434  \n",
       "7886     We have carried out a calculation of the inc...  1.059579  \n",
       "1984     The cross section for central diffractive Hi...  1.066204  \n",
       "13288    Neutral and charged current deep inelastic s...  1.066468  \n",
       "14716    We consider a highly unconventional approach...  1.097358  \n",
       "9387     An overview of latest top quark pair product...  1.117400  \n",
       "6433     I discuss single top quark production at the...  1.122415  \n",
       "1428     We consider the regions of the MSSM paramete...  1.133265  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search function\n",
    "search_faiss(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad87fce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG\n",
    "def rag_search(query, top_k=3):\n",
    "    # Get documents\n",
    "    docs = search_faiss(query, top_k=top_k)\n",
    "    # Create a prompt for OpenAI\n",
    "    prompt = f\"\"\"\n",
    "    Bas√°ndote √öNICAMENTE en los siguientes documentos relevantes, responde la consulta del usuario.\n",
    "\n",
    "    CONSULTA: \"{query}\"\n",
    "\n",
    "    DOCUMENTOS RELEVANTES:\n",
    "    \"\"\"\n",
    "    \n",
    "    for idx, (_, row) in enumerate(docs.iterrows(), 1):\n",
    "        prompt += f\"\"\"\n",
    "    Documento {idx}:\n",
    "    T√≠tulo: {row['title']}\n",
    "    Resumen: {row['abstract']}\n",
    "    Distancia sem√°ntica: {row['Distance']:.4f}\n",
    "    ---\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt += \"\"\"\n",
    "    INSTRUCCIONES:\n",
    "    1. Resume la informaci√≥n m√°s relevante de estos documentos para responder la consulta\n",
    "    2. Explica por qu√© estos documentos son relevantes para la consulta\n",
    "    3. Identifica los conceptos clave y metodolog√≠as mencionadas\n",
    "    4. Si hay resultados o conclusiones importantes, incl√∫yelos\n",
    "    5. Mant√©n un enfoque cient√≠fico y preciso\n",
    "    \n",
    "    Estructura tu respuesta en:\n",
    "    - Resumen de hallazgos principales\n",
    "    - Relevancia de los documentos\n",
    "    - Conceptos clave identificados\n",
    "    \"\"\"\n",
    "    # Generate response using OpenAI\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4.1\",\n",
    "        input=prompt\n",
    "    )\n",
    "    return response.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb1352c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta de ChatGPT:\n",
      "**Resumen de hallazgos principales:**\n",
      "\n",
      "Ninguno de los documentos relevantes proporciona una medici√≥n directa o c√°lculo expl√≠cito de las secciones eficaces (cross sections) de producci√≥n de \"diphotons\" (pares de fotones). Sin embargo, los documentos abordan temas relacionados, como la medici√≥n de secciones eficaces diferenciales en distintos procesos en colisionadores, la producci√≥n de bosones y dibosones (pares de bosones, entre ellos posibles combinaciones de bosones electrod√©biles) y la producci√≥n de part√≠culas junto a jet en escenarios del Modelo Est√°ndar y MSSM.\n",
      "\n",
      "- El Documento 1 estudia la producci√≥n de piones en colisiones prot√≥n-berilio a diversas energ√≠as y proporciona mediciones detalladas de las secciones eficaces diferenciales para estos procesos.\n",
      "- El Documento 2 aborda la producci√≥n del bos√≥n de Higgs neutral m√°s ligero del MSSM asociado con un jet y analiza las distribuciones de secciones eficaces diferenciales (en pseudorapidez y momento transversal) para estos eventos en el LHC y Tevatron.\n",
      "- El Documento 3 revisa mediciones electrod√©biles en el Tevatron, incluyendo la observaci√≥n de producci√≥n de pares de bosones (dibosones) como WŒ≥, ZŒ≥, WW, y WZ, comentando que la producci√≥n de pares de bosones ZZ (de los cuales pueden surgir dos fotones en ciertos decaimientos, aunque esto no es equivalente directamente a producci√≥n de diphotons) est√° justo por debajo del umbral de observaci√≥n con los datos actuales.\n",
      "\n",
      "**Relevancia de los documentos:**\n",
      "\n",
      "Estos documentos no discuten directamente la producci√≥n de pares de fotones (diphoton production), pero son relevantes porque:\n",
      "- Proveen contexto sobre c√≥mo se miden y presentan secciones eficaces de producci√≥n de estados finales espec√≠ficos en experimentos de f√≠sica de altas energ√≠as.\n",
      "- Describen metodolog√≠as generales y enfoques de an√°lisis para la medici√≥n de secciones eficaces diferenciales, que pueden ser aplicables a la producci√≥n de diphotons.\n",
      "- El an√°lisis de producci√≥n de dibosones electrod√©biles y de bosones m√°s un jet es conceptualmente cercano a la producci√≥n de diphotons, ya que en f√≠sica de part√≠culas estas t√©cnicas experimentales y an√°lisis de datos suelen ser compartidos entre los distintos canales de producci√≥n.\n",
      "\n",
      "**Conceptos clave identificados:**\n",
      "\n",
      "- **Secci√≥n eficaz diferencial**: Expresada como $d^2\\sigma/dpd\\Omega$, describe la probabilidad de producir part√≠culas con ciertos valores de momento y √°ngulo en una colisi√≥n.\n",
      "- **Par√°metrizaciones de la secci√≥n eficaz**: Por ejemplo, la parametrizaci√≥n de Sanford-Wang utilizada en el Documento 1 para ajustar datos experimentales.\n",
      "- **Producci√≥n de bosones (y dibosones) en colisionadores**: En el Documento 3 se mencionan combinaciones de W, Z y fot√≥n (Œ≥), adem√°s de discusiones sobre la escala de las secciones eficaces.\n",
      "- **Distribuciones de momento transversal y pseudorapidez**: An√°lisis detallados de c√≥mo var√≠a la producci√≥n de part√≠culas seg√∫n estas variables, relevantes en la b√∫squeda y medici√≥n de canales espec√≠ficos como diphotons.\n",
      "- **Modelos te√≥ricos aplicados**: Incluyendo el Modelo Est√°ndar, extensiones como el MSSM, y benchmarks te√≥ricos utilizados para comparar resultados experimentales.\n",
      "\n",
      "**Conclusi√≥n:**  \n",
      "Si bien ninguno de los documentos proporciona una medici√≥n directa de la secci√≥n eficaz de producci√≥n de diphotons, describen la metodolog√≠a y el contexto experimental relevante para este tipo de mediciones en f√≠sica de altas energ√≠as. En particular, destacan c√≥mo se presentan y analizan secciones eficaces diferenciales, la producci√≥n de bosones y dibosones, y las t√©cnicas de ajuste y comparaci√≥n con modelos te√≥ricos.\n"
     ]
    }
   ],
   "source": [
    "response = rag_search(query)\n",
    "print(\"Respuesta de ChatGPT:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bfbd5ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_search_methods(query, top_k=10):\n",
    "    print(f\"=== COMPARACI√ìN DE M√âTODOS PARA: '{query}' ===\\n\")\n",
    "    \n",
    "    # 1. Obtener resultados de cada m√©todo\n",
    "    tfidf_results = search_tfidf(query)\n",
    "    tfidf_ids = tfidf_results['Identificador'].tolist()\n",
    "        \n",
    "    bm25_results = search_bm25(query)\n",
    "    bm25_ids = bm25_results['Identificador'].tolist()\n",
    "    \n",
    "    faiss_results = search_faiss(query, top_k)\n",
    "    faiss_ids = faiss_results['id'].tolist()\n",
    "\n",
    "    # 2. An√°lisis de documentos en com√∫n (por ID)\n",
    "    print(\"\\nüìä AN√ÅLISIS DE DOCUMENTOS EN COM√öN (por ID):\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Intersecciones entre m√©todos usando IDs\n",
    "    tfidf_bm25_common = set(tfidf_ids) & set(bm25_ids)\n",
    "    tfidf_faiss_common = set(tfidf_ids) & set(faiss_ids)\n",
    "    bm25_faiss_common = set(bm25_ids) & set(faiss_ids)\n",
    "    all_common = set(tfidf_ids) & set(bm25_ids) & set(faiss_ids)\n",
    "\n",
    "    print(f\"‚Ä¢ TF-IDF ‚à© BM25: {len(tfidf_bm25_common)} documentos\")\n",
    "    print(f\"‚Ä¢ TF-IDF ‚à© FAISS: {len(tfidf_faiss_common)} documentos\")\n",
    "    print(f\"‚Ä¢ BM25 ‚à© FAISS: {len(bm25_faiss_common)} documentos\")\n",
    "    print(f\"‚Ä¢ Com√∫n a los 3 m√©todos: {len(all_common)} documentos\")\n",
    "    \n",
    "    # 3. Mostrar documentos comunes a los 3 m√©todos\n",
    "    if all_common:\n",
    "        print(f\"\\nüéØ DOCUMENTOS COMUNES A LOS 3 M√âTODOS:\")\n",
    "        print(\"-\" * 80)\n",
    "        for i, doc_id in enumerate(all_common, 1):\n",
    "            # Buscar el documento por ID\n",
    "            doc_info = data[data['id'] == doc_id].iloc[0]\n",
    "            print(f\"{i}. ID: {doc_id}\")\n",
    "            print(f\"   T√çTULO: {doc_info['title']}\")\n",
    "            print(f\"   RESUMEN: {doc_info['abstract'][:150]}...\")\n",
    "            print(f\"   {'='*70}\")\n",
    "    else:\n",
    "        print(\"‚ùå No hay documentos comunes a los 3 m√©todos\")\n",
    "    \n",
    "    # 4. Mostrar documentos comunes por pares\n",
    "    print(f\"\\nüìã DOCUMENTOS COMUNES POR PARES:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Solo en TF-IDF y BM25 (no en FAISS)\n",
    "    only_tfidf_bm25 = tfidf_bm25_common - all_common\n",
    "    if only_tfidf_bm25:\n",
    "        print(f\"\\nüî∏ Solo en TF-IDF y BM25 ({len(only_tfidf_bm25)} docs):\")\n",
    "        for doc_id in list(only_tfidf_bm25)[:3]:  # Mostrar solo los primeros 3\n",
    "            doc_title = data[data['id'] == doc_id]['title'].iloc[0]\n",
    "            print(f\"   ‚Ä¢ ID {doc_id}: {doc_title[:60]}...\")\n",
    "    \n",
    "    # Solo en TF-IDF y FAISS (no en BM25)\n",
    "    only_tfidf_faiss = tfidf_faiss_common - all_common\n",
    "    if only_tfidf_faiss:\n",
    "        print(f\"\\nüî∏ Solo en TF-IDF y FAISS ({len(only_tfidf_faiss)} docs):\")\n",
    "        for doc_id in list(only_tfidf_faiss)[:3]:\n",
    "            doc_title = data[data['id'] == doc_id]['title'].iloc[0]\n",
    "            print(f\"   ‚Ä¢ ID {doc_id}: {doc_title[:60]}...\")\n",
    "    \n",
    "    # Solo en BM25 y FAISS (no en TF-IDF)\n",
    "    only_bm25_faiss = bm25_faiss_common - all_common\n",
    "    if only_bm25_faiss:\n",
    "        print(f\"\\nüî∏ Solo en BM25 y FAISS ({len(only_bm25_faiss)} docs):\")\n",
    "        for doc_id in list(only_bm25_faiss)[:3]:\n",
    "            doc_title = data[data['id'] == doc_id]['title'].iloc[0]\n",
    "            print(f\"   ‚Ä¢ ID {doc_id}: {doc_title[:60]}...\")\n",
    "\n",
    "    # 5. An√°lisis de ordenamiento por ID\n",
    "    print(f\"\\nüìà COMPARACI√ìN DE ORDENAMIENTO POR ID:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Crear tabla de comparaci√≥n con IDs y t√≠tulos\n",
    "    comparison_data = []\n",
    "    for pos in range(0, top_k):\n",
    "        row = {'Posici√≥n': pos + 1}\n",
    "        \n",
    "        # TF-IDF\n",
    "        if pos < len(tfidf_ids):\n",
    "            tfidf_id = tfidf_ids[pos]\n",
    "            tfidf_title = data[data['id'] == tfidf_id]['title'].iloc[0]\n",
    "            row['TF-IDF'] = f\"ID {tfidf_id}: {tfidf_title[:35]}...\"\n",
    "        else:\n",
    "            row['TF-IDF'] = \"N/A\"\n",
    "            \n",
    "        # BM25\n",
    "        if pos < len(bm25_ids):\n",
    "            bm25_id = bm25_ids[pos]\n",
    "            bm25_title = data[data['id'] == bm25_id]['title'].iloc[0]\n",
    "            row['BM25'] = f\"ID {bm25_id}: {bm25_title[:35]}...\"\n",
    "        else:\n",
    "            row['BM25'] = \"N/A\"\n",
    "            \n",
    "        # FAISS\n",
    "        if pos < len(faiss_ids):\n",
    "            faiss_id = faiss_ids[pos]\n",
    "            faiss_title = data[data['id'] == faiss_id]['title'].iloc[0]\n",
    "            row['FAISS'] = f\"ID {faiss_id}: {faiss_title[:35]}...\"\n",
    "        else:\n",
    "            row['FAISS'] = \"N/A\"\n",
    "            \n",
    "        comparison_data.append(row)\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    \n",
    "    # 6. M√©tricas de similitud usando IDs\n",
    "    print(f\"\\nüìä M√âTRICAS DE SIMILITUD POR ID:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    def similarity_ids(list1, list2, k=top_k):\n",
    "        set1 = set(list1[:k])\n",
    "        set2 = set(list2[:k])\n",
    "        intersection = len(set1 & set2)\n",
    "        union = len(set1 | set2)\n",
    "        return intersection / union if union > 0 else 0\n",
    "    \n",
    "    tfidf_bm25_sim = similarity_ids(tfidf_ids, bm25_ids)\n",
    "    tfidf_faiss_sim = similarity_ids(tfidf_ids, faiss_ids)\n",
    "    bm25_faiss_sim = similarity_ids(bm25_ids, faiss_ids)\n",
    "    \n",
    "    print(f\"‚Ä¢ Similitud TF-IDF vs BM25: {tfidf_bm25_sim:.3f}\")\n",
    "    print(f\"‚Ä¢ Similitud TF-IDF vs FAISS: {tfidf_faiss_sim:.3f}\")\n",
    "    print(f\"‚Ä¢ Similitud BM25 vs FAISS: {bm25_faiss_sim:.3f}\")\n",
    "    \n",
    "    # 7. Resumen de diferencias\n",
    "    print(f\"\\nüìù RESUMEN DE DIFERENCIAS:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"‚Ä¢ TF-IDF: Enfoque estad√≠stico, mejor para coincidencias exactas de t√©rminos\")\n",
    "    print(\"‚Ä¢ BM25: Mejora de TF-IDF, considera frecuencia de documentos y longitud\")\n",
    "    print(\"‚Ä¢ FAISS: B√∫squeda sem√°ntica, encuentra documentos conceptualmente similares\")\n",
    "    \n",
    "    # 8. An√°lisis de rendimiento\n",
    "    print(f\"\\n‚ö° AN√ÅLISIS DE RENDIMIENTO:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"‚Ä¢ Documentos √∫nicos por m√©todo:\")\n",
    "    print(f\"  - Solo TF-IDF: {len(set(tfidf_ids) - set(bm25_ids) - set(faiss_ids))}\")\n",
    "    print(f\"  - Solo BM25: {len(set(bm25_ids) - set(tfidf_ids) - set(faiss_ids))}\")\n",
    "    print(f\"  - Solo FAISS: {len(set(faiss_ids) - set(tfidf_ids) - set(bm25_ids))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6abec479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPARACI√ìN DE M√âTODOS PARA: 'diphoton production cross sections' ===\n",
      "\n",
      "\n",
      "üìä AN√ÅLISIS DE DOCUMENTOS EN COM√öN (por ID):\n",
      "============================================================\n",
      "‚Ä¢ TF-IDF ‚à© BM25: 0 documentos\n",
      "‚Ä¢ TF-IDF ‚à© FAISS: 1 documentos\n",
      "‚Ä¢ BM25 ‚à© FAISS: 0 documentos\n",
      "‚Ä¢ Com√∫n a los 3 m√©todos: 0 documentos\n",
      "‚ùå No hay documentos comunes a los 3 m√©todos\n",
      "\n",
      "üìã DOCUMENTOS COMUNES POR PARES:\n",
      "------------------------------------------------------------\n",
      "\n",
      "üî∏ Solo en TF-IDF y FAISS (1 docs):\n",
      "   ‚Ä¢ ID 706.0851: Electroweak measurements at the Tevatron...\n",
      "\n",
      "üìà COMPARACI√ìN DE ORDENAMIENTO POR ID:\n",
      "================================================================================\n",
      " Posici√≥n                                              TF-IDF                                                BM25                                               FAISS\n",
      "        1 ID 704.0001: Calculation of prompt diphoton prod... ID 707.1256: The geometry of the critical set of... ID 707.2375: Pion Production by Protons on a Thi...\n",
      "        2 ID 707.2294: Search for a High-Mass Diphoton Sta... ID 707.0364: Polarization types of isogenous Pry... ID 705.2744: Distributions for MSSM Higgs boson ...\n",
      "        3 ID 706.0851: Electroweak measurements at the Tev... ID 707.1108: Permutation binomials over finite f... ID 706.0851: Electroweak measurements at the Tev...\n",
      "        4 ID 705.4313: Projectile Fragmentation of $^{86}$... ID 705.0325: The order of the largest complete m... ID 705.3884: Inclusive electron spectrum in the ...\n",
      "        5 ID 706.2813: Measurement of the Total Hadronic C... ID 706.4102: Ramsey numbers and the size of grap...    ID 704.1985: Electromagnetic Higgs production...\n",
      "        6 ID 706.2117: Novel Master Formula for Twist-3 So... ID 707.3316: Morita equivalences of cyclotomic H... ID 707.0118: Proton Structure Functions at High ...\n",
      "        7 ID 705.0349: New isotope 44Si and systematics of...  ID 705.3749: Difference sets and shifted primes... ID 707.1546: Producing an Intense, Cool Muon Bea...\n",
      "        8 ID 706.2693: Reaction cross sections for proton ... ID 707.1102: Nonexistence of permutation binomia... ID 706.0701: Top Pair Production cross-section a...\n",
      "        9 ID 705.4249: Extrapolation of neutron-rich isoto...      ID 707.2612: Exceptional covers of surfaces... ID 705.2431: Higher-order Threshold Corrections ...\n",
      "       10 ID 705.1051: Quasi-elastic neutrino charged-curr... ID 707.3672: Products of irreducible random matr... ID 704.1429: Light stops in the MSSM parameter s...\n",
      "\n",
      "üìä M√âTRICAS DE SIMILITUD POR ID:\n",
      "--------------------------------------------------\n",
      "‚Ä¢ Similitud TF-IDF vs BM25: 0.000\n",
      "‚Ä¢ Similitud TF-IDF vs FAISS: 0.053\n",
      "‚Ä¢ Similitud BM25 vs FAISS: 0.000\n",
      "\n",
      "üìù RESUMEN DE DIFERENCIAS:\n",
      "==================================================\n",
      "‚Ä¢ TF-IDF: Enfoque estad√≠stico, mejor para coincidencias exactas de t√©rminos\n",
      "‚Ä¢ BM25: Mejora de TF-IDF, considera frecuencia de documentos y longitud\n",
      "‚Ä¢ FAISS: B√∫squeda sem√°ntica, encuentra documentos conceptualmente similares\n",
      "\n",
      "‚ö° AN√ÅLISIS DE RENDIMIENTO:\n",
      "--------------------------------------------------\n",
      "‚Ä¢ Documentos √∫nicos por m√©todo:\n",
      "  - Solo TF-IDF: 9\n",
      "  - Solo BM25: 10\n",
      "  - Solo FAISS: 9\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar comparaci√≥n\n",
    "comparison_results = compare_search_methods(query, top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a41027a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_ranking_overlap(query, top_k=10):\n",
    "    \"\"\"\n",
    "    Mide similitud entre rankings contando cu√°ntos documentos del top-k coinciden\n",
    "    \"\"\"\n",
    "    print(f\"=== SIMILITUD ENTRE RANKINGS (Top-{top_k}) ===\")\n",
    "    print(f\"Consulta: '{query}'\\n\")\n",
    "    \n",
    "    # 1. Obtener resultados de cada m√©todo\n",
    "    tfidf_results = search_tfidf(query, top_k)\n",
    "    tfidf_ids = set(tfidf_results['Identificador'].tolist())\n",
    "    \n",
    "    bm25_results = search_bm25(query, top_k)\n",
    "    bm25_ids = set(bm25_results['Identificador'].tolist())\n",
    "    \n",
    "    faiss_results = search_faiss(query, top_k)\n",
    "    faiss_ids = set(faiss_results['id'].tolist())\n",
    "    \n",
    "    # 2. Contar documentos coincidentes\n",
    "    print(\"üìä DOCUMENTOS COINCIDENTES:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Intersecciones entre pares\n",
    "    tfidf_bm25_overlap = len(tfidf_ids & bm25_ids)\n",
    "    tfidf_faiss_overlap = len(tfidf_ids & faiss_ids)\n",
    "    bm25_faiss_overlap = len(bm25_ids & faiss_ids)\n",
    "    \n",
    "    # Intersecci√≥n de los tres m√©todos\n",
    "    all_three_overlap = len(tfidf_ids & bm25_ids & faiss_ids)\n",
    "    \n",
    "    print(f\"TF-IDF ‚à© BM25:     {tfidf_bm25_overlap}/{top_k} documentos ({tfidf_bm25_overlap/top_k*100:.1f}%)\")\n",
    "    print(f\"TF-IDF ‚à© FAISS:    {tfidf_faiss_overlap}/{top_k} documentos ({tfidf_faiss_overlap/top_k*100:.1f}%)\")\n",
    "    print(f\"BM25 ‚à© FAISS:      {bm25_faiss_overlap}/{top_k} documentos ({bm25_faiss_overlap/top_k*100:.1f}%)\")\n",
    "    print(f\"Com√∫n a los 3:     {all_three_overlap}/{top_k} documentos ({all_three_overlap/top_k*100:.1f}%)\")\n",
    "    \n",
    "    # 3. Calcular similitud normalizada (0-1)\n",
    "    print(f\"\\nüìà SIMILITUD NORMALIZADA:\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    sim_tfidf_bm25 = tfidf_bm25_overlap / top_k\n",
    "    sim_tfidf_faiss = tfidf_faiss_overlap / top_k\n",
    "    sim_bm25_faiss = bm25_faiss_overlap / top_k\n",
    "    sim_all_three = all_three_overlap / top_k\n",
    "    \n",
    "    print(f\"TF-IDF vs BM25:    {sim_tfidf_bm25:.3f}\")\n",
    "    print(f\"TF-IDF vs FAISS:   {sim_tfidf_faiss:.3f}\")\n",
    "    print(f\"BM25 vs FAISS:     {sim_bm25_faiss:.3f}\")\n",
    "    print(f\"Consenso (3 m√©todos): {sim_all_three:.3f}\")\n",
    "    \n",
    "    # 4. Similitud promedio\n",
    "    avg_similarity = (sim_tfidf_bm25 + sim_tfidf_faiss + sim_bm25_faiss) / 3\n",
    "    print(f\"\\nSimilitud promedio: {avg_similarity:.3f}\")\n",
    "    \n",
    "    # 5. Interpretaci√≥n\n",
    "    if avg_similarity >= 0.7:\n",
    "        interpretation = \"MUY ALTA similitud - Los m√©todos coinciden mucho\"\n",
    "    elif avg_similarity >= 0.5:\n",
    "        interpretation = \"ALTA similitud - Buen consenso entre m√©todos\"\n",
    "    elif avg_similarity >= 0.3:\n",
    "        interpretation = \"MEDIA similitud - Consenso moderado\"\n",
    "    else:\n",
    "        interpretation = \"BAJA similitud - Los m√©todos difieren significativamente\"\n",
    "    \n",
    "    print(f\"Interpretaci√≥n: {interpretation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "48d9c217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SIMILITUD ENTRE RANKINGS (Top-10) ===\n",
      "Consulta: 'diphoton production cross sections'\n",
      "\n",
      "üìä DOCUMENTOS COINCIDENTES:\n",
      "========================================\n",
      "TF-IDF ‚à© BM25:     0/10 documentos (0.0%)\n",
      "TF-IDF ‚à© FAISS:    1/10 documentos (10.0%)\n",
      "BM25 ‚à© FAISS:      0/10 documentos (0.0%)\n",
      "Com√∫n a los 3:     0/10 documentos (0.0%)\n",
      "\n",
      "üìà SIMILITUD NORMALIZADA:\n",
      "==============================\n",
      "TF-IDF vs BM25:    0.000\n",
      "TF-IDF vs FAISS:   0.100\n",
      "BM25 vs FAISS:     0.000\n",
      "Consenso (3 m√©todos): 0.000\n",
      "\n",
      "Similitud promedio: 0.033\n",
      "Interpretaci√≥n: BAJA similitud - Los m√©todos difieren significativamente\n"
     ]
    }
   ],
   "source": [
    "overlap_results = measure_ranking_overlap(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
